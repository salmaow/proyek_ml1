# -*- coding: utf-8 -*-
"""Copy of ml1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AkoapAls1aSG9Cx4QeMKpK5hyk33LhJz

# ML Terapan - Salma Oktarina
# Polycystic Ovary Syndrome PCOS
Sumber: https://www.kaggle.com/datasets/lucass0s0/polycystic-ovary-syndrome-pcos

## Import Libraries
"""

# Import library
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, mean_squared_error
import zipfile

"""# Loading Data"""

# Mout google drive
from google.colab import drive
drive.mount('/content/drive')
path = '/content/drive/MyDrive/proyek_ml1/'

# Load dataset
try:
    df = pd.read_csv(path + "pcos_rotterdam_balanceado.csv")
    print("Dataset sukses dimuat")
except FileNotFoundError:
    print("Error: 'pcos_rotterdam_balanceado.csv'. Dataset tidak ditemukan.")

"""# Data Understanding"""

# Melihat 5 baris pertama data
print("Data 5 Baris Pertama")
df.head()

# Informasi dataset
print("Informasi Dataset:")
print(df.info())

"""- Dataset berjumlah 3000 entri data.
- Terdapat 5 kolom fitur tanpa nilai yang hilang, ini menunjukkan data bersih dan siap digunakan untuk analisis lebih lanjut.
- Termasuk data kuantitatif, karena kolom bertipe numerik (int64 dan float64).
- Mencakup faktor medis seperti umur, indeks massa tubuh, ketidakteraturan siklus menstruasi, kadar hormon testosteron (ng/dL), dan jumlah folikel antral berdasarkan USG, yang digunakan untuk memprediksi label target PCOS_Diagnosis (indikasi PCOS).

"""

# Deskirpsi statistik
print("Deskripsi Statistik:")
df.describe()

"""- Rata-rata usia pasien berkisar 30 tahun dan nilai maksimumnya 44 tahun.
- Indek massa tubuh normalnya berkisar 18,5 hingga 24,9. Dilihat dari data nilai terkecilnya 8,5 artinya termasuk kurus dan nilai terbesarnya 44,7 termasuk kategori obesitas.
- Kadar normal tertosteron berkisar 15â€”70 nanogram per desiliter darah. Bisa dilihat pada dataset kadar terkecil yaitu 20,5 dan kadar terbesar 136,4.
- Jumlah antral folikel normalnya seitar 9 hingga 19 buah. Dan pada dataset terkecil 3 dan terbesar 39.
- Untuk Mestrual Irregularity dan PCOS Diagnosis nilai 0 berarti tidak lancar dan tidak terindikasi, nilai 1 berarti lancar dan terindikasi.
"""

# Analisis missing value
print("Analisis Missing Value:")
print(df.isna().sum())

"""- Tidak ada missing value, yang artinya data siap digunakan untuk analisis lebih lanjut."""

# Analisis duplikasi data
print("Analisis Duplikasi Data:")
print(df.duplicated().sum())

"""- Terlihat tidak ada duplikasi data artinya data bersih sekali."""

# Visualisaasi distribusi fitur
print("Distribusi Fitur")
df.hist(figsize=(10, 10))
plt.tight_layout()
plt.show()

"""- Dilihat pada visualisasi fitur di atas, distribusi data bagus, nilainya juga masuk akal."""

# Visualisasi box plot untuk melihat outliers
print("Box Plot Fitur")
plt.figure(figsize=(15, 8))
sns.boxplot(data=df, orient='h')
plt.title("Box Plot Fitur")
plt.show()

"""- Terlihat kadar testosteron terdapat nilai yang rentangnya lumayan jauh juga."""

# Visualisasi Distribusi Target ('PCOS_Diagnosis')
print("PCOS Distribusi:")
pcos_counts = df['PCOS_Diagnosis'].value_counts()
print(pcos_counts)
sns.countplot(x='PCOS_Diagnosis', data=df)
plt.title('Distribusi dari PCOS (0: Tidak PCOS, 1: PCOS)')
plt.show()

"""- Ketimpangan jumlah distribusi data, dimana jumlah tidak terindikasi (nilai 0) lebih banyak dari jumlah yang terindikasi. Ditakutkan model memiliki kecenderungan pada kelas mayoritas."""

# HEatmap korelasi antar fitur
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Heatmap Korelasi Antar Fitur")
plt.show()

"""- Berdasarkan matriks korelasi, terlihat fitur yang paling berkorelasi positif terhadap kemungkina terindikasi PCOS (PCOS_Diagnosis) adalah jumlah folikel antral (0.87), kadar testosteron dan ketidakteraturan mestruasi (0.78), dan indeks massa tubuh (0.29).
- Hal ini menunjukkan bahwa jumlah folikel antral, kadar testosteron, dan ketidakteraturan mestruasi berkaitan erat dengan adanya indikasi PCOS.

# Data Preparation
"""

# Penanganan outliers
print("Menangani Outliers dengan Metode IQR")

features = df.drop('PCOS_Diagnosis', axis=1).columns

for column in features:
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Hapus outlier
    initial_lower = df[df[column] < lower_bound].shape[0]
    initial_upper = df[df[column] > upper_bound].shape[0]

    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])

    capped_lower = df[df[column] < lower_bound].shape[0] # Should be 0
    capped_upper = df[df[column] > upper_bound].shape[0] # Should be 0

    if initial_lower > 0 or initial_upper > 0:
        print(f"Outliers di '{column}': {initial_lower} lower, {initial_upper} upper.")
    else:
        print(f"Tidak outlier ditemukan pada '{column}'.")


print("Plotting boxplots setelah outlier")
plt.figure(figsize=(20, 10))
sns.boxplot(data=df.drop('PCOS_Diagnosis', axis=1), orient='h')
plt.title("Box Plot Fitur (Setelah penanganan IQR)")
plt.show()

"""- Outliers teratasi, distribusi datanya sudah merata.

# Split Data
"""

# Pisahkan fitur dan target
X = df[['Age', 'BMI', 'Menstrual_Irregularity', 'Testosterone_Level(ng/dL)', 'Antral_Follicle_Count']]
y = df['PCOS_Diagnosis']
print("\nFeatures (X) and Target (y) separated.")
print("Shape of X:", X.shape)
print("Shape of y:", y.shape)

# Normalisasi data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("\nScaling data (5 baris pertama):")
print(X_scaled[:5])

"""- Setelah di normalisasi, rentang data ada pada 0 sampai 1, artinya normalisasi berhasil dilakukan"""

# Split data (training 80% dan testing 20%)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
print("Train set Outcome distribution:\n", y_train.value_counts(normalize=True))
print("Test set Outcome distribution:\n", y_test.value_counts(normalize=True))

print("\nData split menjadi training dan testing sets.")
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""- Pemisahan dataset baik itu pelatihan dan pengujian yang optimal yaitu 2400 sampel untuk training dan 600 sampel untuk testing."""

# Penanganan data tidak seimbang
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

"""# Modeling"""

print("Modeling")

# Model 1: Logistic Regression
print("\nTraining Logistic Regression Classifier...")
lr = LogisticRegression(random_state=42, solver='liblinear') # liblinear bagus untuk dataset kecil
lr.fit(X_train_resampled, y_train_resampled)

# Model 2: Random Forest
print("\nTraining Random Forest Classifier...")
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_resampled, y_train_resampled)

# Hyperparameter Tuning untuk model terpilih ( Random Forest)
print("\nHyperparameter Tuning Untuk Random Forest Menggunakan GridSearchCV")

# Tentukan parameter grid yang lebih kecil untuk contoh cepat
param_grid_rf = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 4, 6],
    'max_features': ['sqrt', 'log2']
}

# Gunakan cross-validation 3-fold saja untuk contoh
rf_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=42),
                       param_grid=param_grid_rf,
                       cv=3,
                       n_jobs=-1,
                       verbose=1,
                       scoring='accuracy')

rf_grid.fit(X_train_resampled, y_train_resampled)

print("\nParameter Terbaik dari Random Forest:")
print(rf_grid.best_params_)

# Model terbaik dari GridSearchCV
best_rf = rf_grid.best_estimator_
print("\nModel Pelatihan Terbaik Random Forest dengan Parameter Optimal.")

"""# Evaluation"""

# Evaluasi metrik
def evaluate_model(y_true, y_pred, model_name):
    print(f"\n--- {model_name} Evaluation ---")
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0) # Menangani kasus dengan tidak ada prediksi positif
    recall = recall_score(y_true, y_pred, zero_division=0)       # Menangani kasus dengan tidak ada positif sebenarnya
    f1 = f1_score(y_true, y_pred, zero_division=0)               # Menangani kasus dengan tidak ada positif
    mse = mean_squared_error(y_true, y_pred) # MSE untuk klasifikasi (0/1 labels)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Mean Squared Error (MSE): {mse:.4f}") # tambah MSE

    print(f"\nConfusion Matrix ({model_name}):")
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues' if 'Logistic Regression' in model_name else ('Greens' if 'Base RF' in model_name else ('Oranges' if 'Tuned RF' in model_name else 'Purples')))
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix - {model_name}')
    plt.show()
    print(f"\nClassification Report ({model_name}):")
    print(classification_report(y_true, y_pred, zero_division=0))
    return accuracy, precision, recall, f1, mse

# Evaluasi Model Logistic Regression
y_pred_lr = lr.predict(X_test)
acc_lr, pre_lr, rec_lr, f1_lr, mse_lr = evaluate_model(y_test, y_pred_lr, "Logistic Regression")

# Evaluasi Model Random Forest (Baseline)
y_pred_rf_base = rf.predict(X_test)
acc_rf_base, pre_rf_base, rec_rf_base, f1_rf_base, mse_rf_base = evaluate_model(y_test, y_pred_rf_base, "Random Forest (Baseline)")

# Evaluasi Model Random Forest (Tuned)
y_pred_rf_tuned = best_rf.predict(X_test)
acc_rf_tuned, pre_rf_tuned, rec_rf_tuned, f1_rf_tuned, mse_rf_tuned = evaluate_model(y_test, y_pred_rf_tuned, "Random Forest (Tuned)")

"""# Kesimpulan Evaluasi"""

print("\n=== Evaluation Summary ===")

results_summary = pd.DataFrame({
    'Model': ['Logistic Regression', 'Random Forest (Baseline)', 'Random Forest (Tuned)'],
    'Accuracy': [acc_lr, acc_rf_base, acc_rf_tuned],
    'Precision': [pre_lr, pre_rf_base, pre_rf_tuned],
    'Recall': [rec_lr, rec_rf_base, rec_rf_tuned],
    'F1 Score': [f1_lr, f1_rf_base, f1_rf_tuned],
    'MSE': [mse_lr, mse_rf_base, mse_rf_tuned]
})

print("\nMetrik Performa Model:")
print(results_summary.round(4)) # dibulatkan 4 angka desimal

print("\nMembandingkan model berdasarkan F1-Score :")
best_f1_model = results_summary.loc[results_summary['F1 Score'].idxmax()]
print(f"Performa model terbaik berdasarkan F1-Score:\n{best_f1_model['Model']} with F1-Score: {best_f1_model['F1 Score']:.4f}")

print("\nMembandingkan model berdasarkan Recall:")
best_recall_model = results_summary.loc[results_summary['Recall'].idxmax()]
print(f"Performal model terbaik berdasarkan Recall:\n{best_recall_model['Model']} with Recall: {best_recall_model['Recall']:.4f}")

print("\nMembandingkan model berdasarkan MSE:")
best_mse_model = results_summary.loc[results_summary['MSE'].idxmin()] # Lower MSE is better
print(f"Model dengan MSE terkecil:\n{best_mse_model['Model']} with MSE: {best_mse_model['MSE']:.4f}")


print("\nProyek Selesai.")

"""- Hasil evaluasi mode di atas, terlihat kemungkinan model overfitting karena hasilnya sempurna (1.00) artinya model hanya menghafal data dan tidak dapat mengenali pola dengan baik."""

